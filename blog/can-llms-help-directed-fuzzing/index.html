<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script>let thunk=()=>{let e=e=>e.trim(),t=e=>e.innerText,n=e=>{let t=e.split(" "),n=t.slice(0,-1).join(" ");return[t.at(-1),n]},a=Array.from(document.getElementsByClassName("author")).map(t).map(e).map(n),r=a[0][0],i=(Array.from(document.getElementsByClassName("affiliation")).filter(e=>"P"===e.nodeName).map(t).map(e),"April 28, 2025"),o="Can Large Language Models Help Directed Fuzzing?",l="An empirical study comparing the performance of Large Language Models against traditional directed fuzzers on program analysis tasks, focusing on path discovery and target reachability using the Fuzzle benchmark framework.";{let e=a.map(e=>`${e[0]}, ${e[1]}`).join(" and "),t=`\n@inproceedings{${(r+"2025"+o.split(" ").slice(0,3).join("")).replace(" ","").replace(/[\p{P}$+<=>^`|~]/gu,"").toLowerCase().trim()},\n  author = {${e}},\n  title = {${o}},\n  abstract = {${l}},\n  booktitle = {ICLR Blogposts 2025},\n  year = {2025},\n  date = {${i}},\n  note = {${window.location.href}},\n  url  = {${window.location.href}}\n}\n  `.trim();document.getElementById("bibtex-box").innerText=t}{let e=a.map(e=>e[0]),t=`\n${e=e.length>2?e[0]+", et al.":2==e.length?e[0]+" & "+e[1]:e[0]}, "${o}", ICLR Blogposts, 2025.\n`.trim();document.getElementById("bibtex-academic-attribution").innerText=t}};document.addEventListener("readystatechange",function(){"complete"===document.readyState&&thunk()});</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Can Large Language Models Help Directed Fuzzing? | Blogposts</title> <meta name="author" content="Haochen Zeng"> <meta name="description" content="An empirical study comparing the performance of Large Language Models against traditional directed fuzzers on program analysis tasks, focusing on path discovery and target reachability using the Fuzzle benchmark framework."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/blogposts/assets/img/iclr_favicon.ico"> <link rel="stylesheet" href="/blogposts/assets/css/main.css"> <link rel="canonical" href="https://sghzeng.github.io/blogposts/blog/can-llms-help-directed-fuzzing/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/blogposts/assets/js/theme.js"></script> <script src="/blogposts/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/blogposts/assets/js/distillpub/template.v2.js"></script> <script src="/blogposts/assets/js/distillpub/transforms.v2.js"></script> <script src="/blogposts/assets/js/distillpub/overrides.js"></script> <d-front-matter> <script async type="text/json">{
      "title": "Can Large Language Models Help Directed Fuzzing?",
      "description": "An empirical study comparing the performance of Large Language Models against traditional directed fuzzers on program analysis tasks, focusing on path discovery and target reachability using the Fuzzle benchmark framework.",
      "published": "April 28, 2025",
      "authors": [
        {
          "author": "Anonymous",
          "authorURL": "",
          "affiliations": [
            {
              "name": "",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> </head> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blogposts//">Blogposts</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blogposts/about/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blogposts/call/">call for blogposts</a> </li> <li class="nav-item "> <a class="nav-link" href="/blogposts/submitting/">submitting</a> </li> <li class="nav-item "> <a class="nav-link" href="/blogposts/reviewing/">reviewing</a> </li> <li class="nav-item "> <a class="nav-link" href="/blogposts/blog/index.html">blog</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2025/" rel="external nofollow noopener noopener noreferrer" target="_blank"><strong>2025</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2024/" rel="external nofollow noopener noopener noreferrer" target="_blank">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blogposts.github.io/2023/" rel="external nofollow noopener noopener noreferrer" target="_blank">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener noopener noreferrer" target="_blank">2022</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Can Large Language Models Help Directed Fuzzing?</h1> <p>An empirical study comparing the performance of Large Language Models against traditional directed fuzzers on program analysis tasks, focusing on path discovery and target reachability using the Fuzzle benchmark framework.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#motivating-example">Motivating Example</a></div> <div><a href="#understanding-the-testbed">Understanding the Testbed</a></div> <ul> <li><a href="#human-expert-chain-of-thought">Human Expert Chain-of-Thought</a></li> </ul> <div><a href="#experiment-results">Experiment Results</a></div> <ul> <li><a href="#selected-llm-models">Selected LLM Models</a></li> <li><a href="#prompts">Prompts</a></li> <li><a href="#testing-methodology">Testing Methodology</a></li> <li><a href="#results-summary">Results Summary</a></li> <li><a href="#observations">Observations</a></li> </ul> <div><a href="#ways-that-llm-might-help">Ways That LLM Might Help</a></div> <div><a href="#appendix">Appendix</a></div> <ul> <li><a href="#maze-program-source-code">Maze Program Source Code</a></li> <li><a href="#o1-chat-dialog">o1 Chat Dialog</a></li> <li><a href="#o1-mini-chat-dialog">o1-mini Chat Dialog</a></li> <li><a href="#gpt-4-chat-dialog">GPT-4 Chat Dialog</a></li> <li><a href="#gpt-4o-chat-dialog">GPT-4o Chat Dialog</a></li> <li><a href="#gpt-4o-mini-chat-dialog">GPT-4o-mini Chat Dialog</a></li> <li><a href="#claude-3-5-sonnet-chat-dialog">Claude 3.5 Sonnet Chat Dialog</a></li> <li><a href="#claude-3-haiku-chat-dialog">Claude 3 Haiku Chat Dialog</a></li> <li><a href="#gemini-1-5-pro-chat-dialog">Gemini 1.5 Pro Chat Dialog</a></li> </ul> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Software testing and bug finding have always been critical challenges in computer security. Among various testing techniques, fuzzing has emerged as one of the most effective approaches for discovering security vulnerabilities. At its core, fuzzing consists of two key components:</p> <ol> <li> <strong>Input Generator</strong>: Produces and mutates test inputs at high speed.</li> <li> <strong>Runtime Monitor</strong>: Detects security violations during execution (e.g., AddressSanitizer).</li> </ol> <p>In many practical scenarios, developers need to focus on testing specific program locations. For example:</p> <ul> <li>Verifying if a newly patched vulnerability is fixed.</li> <li>Testing recently modified code.</li> <li>Checking potential bugs reported by static analyzers.</li> </ul> <p>Directed fuzzing is a testing technique that automatically generates inputs attempting to reach and trigger buggy program states at specific target locations.</p> <p>Traditional directed fuzzing techniques have long faced challenges when it comes to handling intricate program structures. But the game is changing. With the rise of Large Language Models (LLMs), we’re witnessing a revolution in program analysis<d-cite key="fang2024large"></d-cite><d-cite key="pei2023can">. These models aren't just about generating text—they're showcasing remarkable abilities in understanding code structures, deciphering semantics, and identifying complex patterns within software. The potential here is enormous. By leveraging LLMs' ability to comprehend and analyze complex program behaviors, we're opening the door to groundbreaking advancements in how we test and secure software systems.</d-cite></p> <p>This leads to an interesting question:</p> <p><strong>Can LLMs assist or improve upon traditional directed fuzzing approaches in efficiently reaching target locations?</strong></p> <p>This blog explores this question by evaluating the performance of various LLMs and comparing them with traditional fuzzers using a maze program synthesized from the Fuzzle benchmark.</p> <p>Our results show that while LLMs exhibit strong reasoning capabilities, they face challenges in effectively generating inputs to reach specific program locations compared to traditional directed fuzzers.</p> <h2 id="motivating-example">Motivating Example</h2> <p>To understand the challenges, let’s look at a simplified example that mimics a vulnerable program:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre></td> <td class="code"><pre><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
</span>
<span class="kt">void</span> <span class="nf">cell_A</span><span class="p">(</span><span class="kt">int</span> <span class="n">choice</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Input value: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">choice</span><span class="p">);</span>

    <span class="c1">// Path 1: value &lt; 0</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">choice</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cell_B</span><span class="p">(</span><span class="n">choice</span><span class="p">);</span>         <span class="c1">// Dead end</span>
    <span class="p">}</span>
    <span class="c1">// Path 2: 0 &lt;= value &lt;= 50</span>
    <span class="k">else</span> <span class="nf">if</span> <span class="p">(</span><span class="n">choice</span> <span class="o">&lt;=</span> <span class="mi">50</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cell_A</span><span class="p">(</span><span class="n">choice</span><span class="p">);</span>         <span class="c1">// Infinite loop</span>
    <span class="p">}</span>
    <span class="c1">// Path 3: value &gt; 50</span>
    <span class="k">else</span> <span class="p">{</span>
        <span class="n">cell_C</span><span class="p">(</span><span class="n">choice</span><span class="p">);</span>         <span class="c1">// Can reach target</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">cell_B</span><span class="p">(</span><span class="kt">int</span> <span class="n">choice</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">choice</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// This condition is always false</span>
        <span class="n">bug</span><span class="p">();</span>           <span class="c1">// Can never reach bug() here</span>
    <span class="p">}</span>
    <span class="c1">// Dead end</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Reached dead end</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">cell_C</span><span class="p">(</span><span class="kt">int</span> <span class="n">choice</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Complex condition determining path</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">choice</span> <span class="o">%</span> <span class="mi">7</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cell_D</span><span class="p">(</span><span class="n">choice</span><span class="p">);</span>    <span class="c1">// Target: potential vulnerability</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">cell_B</span><span class="p">(</span><span class="n">choice</span><span class="p">);</span>    <span class="c1">// Return to dead end</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">cell_D</span><span class="p">(</span><span class="kt">int</span> <span class="n">choice</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">bug</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="nf">bug</span><span class="p">(){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Found vulnerability!</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">abort</span><span class="p">();</span>  <span class="c1">// Vulnerability triggered</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">input</span><span class="p">;</span>
    <span class="n">scanf</span><span class="p">(</span><span class="s">"%d"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">);</span>    <span class="c1">// Read user input</span>
    <span class="n">cell_A</span><span class="p">(</span><span class="n">input</span><span class="p">);</span>          <span class="c1">// Start exploration</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></td> </tr></tbody></table></code></pre></figure> <h3 id="understanding-the-example">Understanding the Example</h3> <p>This code simulates a program with a potential vulnerability in <code class="language-plaintext highlighter-rouge">cell_D</code> that we want to trigger. To reach it:</p> <ol> <li>The program takes a single integer input.</li> <li>Starting from <code class="language-plaintext highlighter-rouge">cell_A</code>, it navigates through different paths based on input conditions.</li> <li>Only inputs that are both greater than 50 <strong>and</strong> divisible by 7 can reach the target <code class="language-plaintext highlighter-rouge">cell_D</code>.</li> <li>All other paths lead to <code class="language-plaintext highlighter-rouge">cell_B</code>, which is a dead end, or loop back to <code class="language-plaintext highlighter-rouge">cell_A</code>, causing infinite recursion.</li> </ol> <p>The purpose of this example is to demonstrate why directed fuzzing is challenging. Even in this simple program, there are several complexities:</p> <ol> <li> <strong>Control Flow Dependencies</strong>: Understanding the caller and callee relationships among functions is essential. This involves analyzing the program’s control flow graph (CFG) to identify paths that can reach the target.</li> <li> <strong>Data Flow Dependencies</strong>: Conditions in the CFG may depend on variables whose values are determined by previous computations or inputs not on the direct path.</li> <li> <strong>Path Condition Solving</strong>: Generating inputs that satisfy all the path conditions involved is crucial.</li> </ol> <p>In our example, to reach <code class="language-plaintext highlighter-rouge">cell_D</code> (our target), a test input must satisfy multiple conditions:</p> <ul> <li>Must be greater than 50 (condition in <code class="language-plaintext highlighter-rouge">cell_A</code>).</li> <li>Must be divisible by 7 (condition in <code class="language-plaintext highlighter-rouge">cell_C</code>).</li> </ul> <h2 id="understanding-the-testbed">Understanding the Testbed</h2> <p>To systematically evaluate how LLMs perform on directed fuzzing tasks, we need a controlled testing environment. This is where the Fuzzle benchmark comes in. Fuzzle synthesizes the bug method into a maze-generation process, where triggering a bug is analogous to finding the maze’s exit. Successfully solving the maze demonstrates a model’s ability to generate correct inputs that reach the buggy function.</p> <p>In this study, we used a 10x10 maze program generated by Fuzzle because. Think of it as a more complex version of our previous example, but instead of 4 cells (<code class="language-plaintext highlighter-rouge">cell_A</code> to <code class="language-plaintext highlighter-rouge">cell_D</code>), it has 100 functions (<code class="language-plaintext highlighter-rouge">func_0</code> through <code class="language-plaintext highlighter-rouge">func_99</code>). Here’s what makes it interesting. Based on preliminary results, only the OpenAI o1 model performed relatively well. Testing larger and more complex maze sizes seemed unnecessary.</p> <ol> <li> <strong>Program Structure</strong>: <ul> <li>Each function represents a cell in the maze.</li> <li>Function calls represent connection paths between cells.</li> <li>The program starts at <code class="language-plaintext highlighter-rouge">func_0</code> (entrance).</li> <li> <code class="language-plaintext highlighter-rouge">func_bug</code> represents our target (exit).</li> </ul> </li> <li> <strong>Navigation Rules</strong>: <ul> <li>Each function reads one byte from the input.</li> <li>Based on this byte’s value, it decides which function to call next.</li> <li>Wrong decisions lead to dead ends or infinite loops.</li> </ul> </li> </ol> <p>The program structure can be visualized as a maze:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/blogposts/assets/img/2025-04-28-can-llms-help-directed-fuzzing/maze_viz-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/blogposts/assets/img/2025-04-28-can-llms-help-directed-fuzzing/maze_viz-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/blogposts/assets/img/2025-04-28-can-llms-help-directed-fuzzing/maze_viz-1400.webp"></source> <img src="/blogposts/assets/img/2025-04-28-can-llms-help-directed-fuzzing/maze_viz.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <strong>White cells</strong>: Functions in the program.</li> <li> <strong>Black cells</strong>: No connection exists between functions.</li> <li> <strong>Yellow cells</strong>: Critical path functions that must be traversed to reach the target.</li> <li> <strong>Entry point (top-left)</strong>: <code class="language-plaintext highlighter-rouge">func_0</code>, where program execution begins.</li> <li> <strong>Target (bottom-right)</strong>: <code class="language-plaintext highlighter-rouge">func_bug</code>, which we aim to reach.</li> </ul> <p>This visualization helps us understand why directed fuzzing is challenging:</p> <ol> <li>The maze is large (100 cells vs. our 4-cell example).</li> <li>Many paths lead to dead ends.</li> <li>The correct path requires satisfying multiple conditions.</li> <li>Some paths may loop back to previously visited functions.</li> </ol> <h3 id="human-expert-chain-of-thought">Human Expert Chain-of-Thought</h3> <p>To trigger the bug, a human expert would approach this problem through the following chain-of-thought:</p> <ol> <li> <strong>Analyze Function Relationships</strong>: Determine caller and callee relationships among all functions.</li> <li> <p><strong>Identify the Critical Path</strong>: Figure out the exact path marked by the yellow cells:</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>func_0 -&gt; func_10 -&gt; func_11 -&gt; func_12 -&gt; func_13 -&gt; func_14 -&gt; func_24 -&gt; func_34 -&gt; func_44 -&gt; func_43 -&gt; func_42 -&gt; func_32 -&gt; func_31 -&gt; func_41 -&gt; func_51 -&gt; func_52 -&gt; func_62 -&gt; func_72 -&gt; func_82 -&gt; func_83 -&gt; func_93 -&gt; func_94 -&gt; func_84 -&gt; func_74 -&gt; func_75 -&gt; func_76 -&gt; func_86 -&gt; func_87 -&gt; func_88 -&gt; func_78 -&gt; func_79 -&gt; func_89 -&gt; func_99 -&gt; func_bug
</code></pre></div> </div> </li> <li> <strong>Collect Path Conditions</strong>: Along this path, collect all the conditions that must be satisfied based on the input bytes read at each function.</li> <li> <strong>Solve the Path Conditions</strong>: Generate the final input that satisfies all these conditions to reach <code class="language-plaintext highlighter-rouge">func_bug</code>.</li> </ol> <h2 id="experiment-results">Experiment Results</h2> <h3 id="selected-llm-models">Selected LLM Models</h3> <p>We evaluated popular LLM models accessible through web interfaces, including:</p> <ul> <li> <strong>OpenAI</strong>: o1, o1-mini, GPT-4, GPT-4o, GPT-4o-mini</li> <li> <strong>Anthropic</strong>: Claude 3.5 Sonnet, Claude 3 Haiku</li> <li> <strong>Google</strong>: Gemini 1.5 Pro</li> </ul> <h3 id="prompts">Prompts</h3> <p><strong>Zero-Shot Prompt</strong></p> <p>We tested whether the LLMs could, without any hints or prior context, directly provide an input that reaches <code class="language-plaintext highlighter-rouge">func_bug</code>. We provided the test program by copying and pasting the source code into the chatbox, followed by the question:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Examine the uploaded code. Provide a call trace starting from the main function to 'func_bug'.
</code></pre></div></div> <p>To clarify potential confusion due to local variables with the same name, we added:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Please note the variable 'c' is a function local variable that only changes with each function call and is determined by the input at the current index.
</code></pre></div></div> <p><strong>Feedback-Driven Approach</strong></p> <p>If the LLM’s initial response was incorrect, we provided feedback indicating the error and asked them to fix it.</p> <p><strong>Chain-of-Thought (CoT) from o1</strong></p> <p>We provided the chain-of-thought generated by o1 to other LLMs to see if it would help them produce the correct answer.</p> <p><strong><a href="#human-expert-chain-of-thought">Human Expert Chain-of-Thought (CoT*)</a></strong></p> <p>We supplied the detailed reasoning steps from a human expert to the LLMs.</p> <h3 id="testing-methodology">Testing Methodology</h3> <p>We designed the testing methodology as follows:</p> <ol> <li> <strong>Zero-Shot Evaluation</strong>: Test if the LLM can directly provide the correct input without any hints. <ul> <li>If <strong>yes</strong>, record success and stop testing.</li> <li>If <strong>no</strong>, proceed to steps 2 and 3 simultaneously.</li> </ul> </li> <li> <strong>Using o1’s CoT</strong>: Provide OpenAI o1’s chain-of-thought to other LLMs and see if they can produce the correct input. <ul> <li>If <strong>yes</strong>, record success and stop testing.</li> <li>If <strong>no</strong>, proceed to step 4.</li> </ul> </li> <li> <strong>Feedback-Driven Correction</strong>: Inform the LLM whether their output is correct or not, hoping it can self-correct and provide the answer. <ul> <li>If <strong>yes</strong>, record success and stop testing.</li> <li>If <strong>no</strong>, proceed to step 4.</li> </ul> </li> <li>**<a href="#human-expert-chain-of-thought">Using Human Expert CoT**</a>: Provide the human expert’s chain-of-thought to the LLMs. <ul> <li>If the LLM makes any mistakes, record failure.</li> <li>If the final answer is correct, record success.</li> </ul> </li> </ol> <h3 id="results-summary">Results Summary</h3> <p>We have redesigned the table to break down the problem into three evaluation criteria:</p> <ol> <li><strong>Correct Caller-Callee Relationships</strong></li> <li><strong>Correct Call Sequence</strong></li> <li><strong>Correct Input</strong></li> </ol> <p>Below is the table summarizing the performance of each model across the different testing methods and evaluation criteria. A checkmark (✔) indicates success, a cross (✖) indicates failure, and N/A indicates that the test was not applicable.</p> <table> <thead> <tr> <th><strong>Test Method</strong></th> <th><strong>Evaluation Criteria</strong></th> <th><strong>o1</strong></th> <th><strong>o1-mini</strong></th> <th><strong>GPT-4</strong></th> <th><strong>GPT-4o</strong></th> <th><strong>GPT-4o-mini</strong></th> <th><strong>Claude 3.5 Sonnet</strong></th> <th><strong>Claude 3 Haiku</strong></th> <th><strong>Gemini 1.5 Pro</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Zero-Shot Prompt</strong></td> <td>Correct Caller-Callee</td> <td>✔</td> <td>✔</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Call Sequence</td> <td>✔</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Input</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td><strong>Feedback-Driven</strong></td> <td>Correct Caller-Callee</td> <td>N/A</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Call Sequence</td> <td>N/A</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Input</td> <td>✔</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td><strong>Using o1’s CoT</strong></td> <td>Correct Caller-Callee</td> <td>N/A</td> <td>✔</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Call Sequence</td> <td>N/A</td> <td>✔</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Input</td> <td>N/A</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td><strong>Using Human Expert CoT</strong></td> <td>Correct Caller-Callee</td> <td>N/A</td> <td>N/A</td> <td>✖</td> <td>✔</td> <td>✖</td> <td>✔</td> <td>✔</td> <td>✔</td> </tr> <tr> <td> </td> <td>Correct Call Sequence</td> <td>N/A</td> <td>N/A</td> <td>✖</td> <td>✔</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> <tr> <td> </td> <td>Correct Input</td> <td>N/A</td> <td>N/A</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> <td>✖</td> </tr> </tbody> </table> <h3 id="observations">Observations</h3> <h4 id="o1"><a href="#gpto1-chat-dialog">o1</a></h4> <p>From the chat dialog, o1 can break down the problem into reasonable subtasks. It found the correct call trace to the target <code class="language-plaintext highlighter-rouge">func_bug</code>. Examining its chain-of-thought, we see that o1 effectively navigated the maze, avoided dead ends and loops, and collected the necessary path conditions. However, it initially provided an incorrect input array due to miscounting indices.</p> <p>Upon informing o1:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The function call trace is correct; however, the input array is wrong. Figure out why and fix it.
</code></pre></div></div> <p>After 2 minutes and 3 seconds of processing, o1 realized the mistake and successfully corrected the error, ultimately providing the correct input.</p> <h4 id="o1-mini"><a href="#gpto1-mini-chat-dialog">o1-mini</a></h4> <p>While o1-mini attempted to analyze the problem, it incorrectly concluded that there is no path from <code class="language-plaintext highlighter-rouge">func_0</code> to <code class="language-plaintext highlighter-rouge">func_bug</code>. When provided with o1’s chain-of-thought, it was able to find the correct path but faced similar issues with variable confusion. Even after feedback, it couldn’t resolve the problem.</p> <h4 id="gpt4o-gpt4o-mini-and-gpt4"> <a href="#gpt4o-chat-dialog">GPT4o</a>, <a href="#gpt4o-mini-chat-dialog">GPT4o-mini</a> and <a href="#gpt4-chat-dialog">GPT4</a> </h4> <p>GPT-4 and its variants struggled with hallucinations and could not correctly determine the caller and callee relationships. Even when given the human expert’s chain-of-thought, only GPT-4o was able to understand and produce the correct call relationships but struggled with solving the path conditions.</p> <h4 id="claude-35-and-gemini-15-pro">Claude 3.5 and Gemini 1.5 Pro</h4> <p>Although these models could identify some function relationships, they suffered from hallucinations, such as assuming <code class="language-plaintext highlighter-rouge">func_15</code> calls <code class="language-plaintext highlighter-rouge">func_21</code>, which was incorrect. They could not find the correct call trace.</p> <h3 id="comparison-with-traditional-directed-fuzzers">Comparison with Traditional Directed Fuzzers</h3> <p>We also evaluated state-of-the-art directed fuzzers on this maze program:</p> <table> <thead> <tr> <th> </th> <th><strong>AFLGo&lt;/d-cite&gt;<d-cite key="bohme2017directed"></d-cite></strong></th> <th><strong>AFL++<d-cite key="fioraldi2020afl"></d-cite></strong></th> <th><strong>DAFL<d-cite key="kim2023dafl"></d-cite></strong></th> <th><strong>SelectFuzz<d-cite key="luo2023selectfuzz"></d-cite></strong></th> <th><strong>Beacon<d-cite key="huang2022beacon"></d-cite></strong></th> </tr> </thead> <tbody> <tr> <td><strong>Time to Exposure (min)</strong></td> <td>4.97</td> <td>0.15</td> <td>0.17</td> <td>3.25</td> <td>1.38</td> </tr> </tbody> </table> <p><strong>Key Findings</strong>:</p> <ol> <li>Traditional directed fuzzers can solve this maze program more efficiently than LLMs.</li> <li>High throughput allows fuzzers to solve the maze without reasoning, relying on rapid random input generation.</li> </ol> <h2 id="ways-that-llm-might-help">Ways That LLM Might Help</h2> <p>Our experiments revealed several insights about using LLMs for directed fuzzing:</p> <p><strong>Pros</strong>:</p> <ol> <li> <strong>Semantic Understanding</strong>: LLMs demonstrated a superior ability to understand program semantics compared to traditional static analysis, which may overlook implicit control and data flow.</li> <li> <strong>Human-Like Reasoning</strong>: LLMs approach problems more like humans, making decisions at a higher level rather than relying solely on predefined algorithms.</li> </ol> <p><strong>Cons</strong>:</p> <ol> <li> <strong>Performance</strong>: LLMs are much slower compared to traditional static and dynamic analysis tools.</li> <li> <strong>Context Window Limitations</strong>: Large programs exceed current LLM context windows, requiring complex chunking strategies. </li> <li> <strong>Hallucinations</strong>: LLMs may generate incorrect or fabricated information.</li> </ol> <p>Recent academic work&lt;/d-cite&gt;<d-cite key="chang2024leveling"></d-cite> has shown promising results by combining LLMs with fuzzing techniques, particularly in automatic generation of fuzz targets and LLM-assisted input generation. Leveraging the reasoning and decision-making capabilities of LLMs, future directions could include:</p> <ol> <li> <strong>Directed Fuzz Introspection</strong>: Using LLMs to debug and identify bottlenecks in the fuzzing process and provide feedback to the fuzzer.</li> <li> <strong>Assisting Static Analysis</strong>: Filtering out false positives and negatives in traditional static analysis.</li> <li> <strong>Path Condition Solving</strong>: Serving as solvers for complex path conditions.</li> <li> <strong>Strategy Generation</strong>: Generating high-level strategies for exploration, complemented by low-level program analysis tools.</li> </ol> <h2 id="appendix">Appendix</h2> <h3 id="maze-program-source-code">Maze Program Source Code</h3> <details> <summary>View Code</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/Wilsons_10x10_0_1_25percent_default_gen.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="o1-chat-dialog">o1 Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/gpto1-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="o1-mini-chat-dialog">o1-mini Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/gpto1-mini-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="gpt-4-chat-dialog">GPT-4 Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/gpt4-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="gpt-4o-chat-dialog">GPT-4o Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/gpt4o-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="gpt-4o-mini-chat-dialog">GPT-4o-mini Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/gpt4o-mini-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="claude-35-sonnet-chat-dialog">Claude 3.5 Sonnet Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/claude-3.5-sonnet-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="claude-3-haiku-chat-dialog">Claude 3 Haiku Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/claude-3-haiku-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> <h3 id="gemini-15-pro-chat-dialog">Gemini 1.5 Pro Chat Dialog</h3> <details> <summary>View Full Dialog</summary> <div class="l-page"> <iframe src="/blogposts/assets/html/2025-04-28-can-llms-help-directed-fuzzing/gemini-1.5-pro-dialog.html" frameborder="0" scrolling="yes" height="500px" width="100%"> </iframe> </div> </details> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <d-bibliography src="/blogposts/assets/bibliography/2025-04-28-can-llms-help-directed-fuzzing.bib"></d-bibliography> <d-article id="bibtex-container" class="related highlight"> For attribution in academic contexts, please cite this work as <pre id="bibtex-academic-attribution">
        PLACEHOLDER FOR ACADEMIC ATTRIBUTION
  </pre> BibTeX citation <pre id="bibtex-box">
        PLACEHOLDER FOR BIBTEX
  </pre> </d-article> <script src="https://utteranc.es/client.js" repo="iclr-blogposts/2025" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>